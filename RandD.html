<!DOCTYPE html>
<html>

<head>
	<meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta http-equiv="X-UA-Compatible" content="ie=edge" />
    <title>Hinda Haned webpage</title>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400" rel="stylesheet" />    
	<link href="css/templatemo-style.css" rel="stylesheet" />
    <link href="css/all.min.css" rel="stylesheet" />
</head>
<!--

Simple House

https://templatemo.com/tm-539-simple-house

-->
<body> 

	<div class="container">
	<!-- Top box -->
		<!-- Logo & Site Name -->
		<div class="placeholder">
			<div class="parallax-window" data-parallax="scroll" data-image-src="img/simple-house-01.jpg">
				<div class="tm-header">
					<div class="row tm-header-inner">
						<div class="col-md-6 col-12">
							<!-- <img src="img/simple-house-logo.png" alt="Logo" class="tm-site-logo" />  -->
							<div class="tm-site-text-box">
								<h1 class="tm-site-title">Hinda Haned</h1>
								<h6 class="tm-site-description">Fair, Transparent and Accountable Data Science</h6>	
							</div>
						</div>
						<nav class="col-md-6 col-12 tm-nav">
							<ul class="tm-nav-ul">
								<li class="tm-nav-li"><a href="index.html" class="tm-nav-link">Home</a></li>
								<li class="tm-nav-li"><a href="research2020.html" class="tm-nav-link active">R&D</a></li>
								<!-- <li class="tm-nav-li"><a href="publications.html" class="tm-nav-link">Publications</a></li> -->
								<li class="tm-nav-li"><a href="news.html" class="tm-nav-link">News</a></li>
								<!-- <li class="tm-nav-li"><a href="contact.html" class="tm-nav-link">Contact</a></li> -->
							</ul>
						</nav>	
					</div>
				</div>
			</div>
		</div>

		<main>
		
        
        <!-- <header class="row tm-welcome-section"> -->
				<!-- <h2 class="col-12 text-lefttm-section-title">Data science in retail</h2> -->
				<!-- <p class="col-12 text-justify"> -->
				<!-- This is a non-exhaustive list of projects I have recently worked on/still working on in my current position:</p> -->
  				<!-- <ul> <li> Forecasting with limited data (<a here href="https://github.com/hindantation/talks/blob/master/Forecasting_march_2019.pdf">sss</a>)</li> -->
              	<!-- <li> xxx</li> -->
                <!-- <li> xxx </li> -->
				<!-- </u> -->
				
		<!-- </header> -->
        <header class="row tm-welcome-section">
				<h2 class="col-12 text-lefttm-section-title">Explainable AI </h2>
				<p class="col-12 text-justify">
				<!-- <li class="col-12 text-justify"> -->
				I focus on developing methods for generating contextualized explanations of algorithmic systems. I particularity focus on challenges of XAI from a practitioner's perspective. Some of the latests works I contributed in the last years on this topic:</p>
				<ul> 
                
                <li> <b>  To Trust or Not to Trust a Regressor: Estimating and Explaining Trustworthiness of Regression Predictions  </b>  This  <a here href="https://arxiv.org/pdf/2104.06982.pdf">paper</a> introduces RETRO-VIZ, a method for (i) estimating and (ii) explaining trustworthiness of regression predictions. It consists of RETRO, a quantitative estimate of the trustworthiness of a prediction, and VIZ, a visual explanation that helps users identify the reasons for the (lack of) trustworthiness of a prediction (ICML HILL workshop 2021). </li>
                
                <li> <b> Why does my model fail? </b>  How does explaining forecasting errors help users accept and/ore trust a model enough to deploy it?  Read more on the algorithm explaining model errors <a href="https://arxiv.org/abs/1908.00085">here</a> (FAT* 2020, best student paper award) </li>

				
				<li> <b> How well do local explanations approximate the actual global model behavior?</b> We develop a new way of evaluating the usefulness of local explanations in understanding global model behavior, read more <a href="https://arxiv.org/abs/1907.03039">here</a> (SIGIR Paris 2019 - FACTS-IR workshop), </li>
				<!-- counterfactual explanations for tree ensembles. This paper extends  counterfcatuals explanations to x and y. https://arxiv.org/pdf/1911.12199.pdf [under review]</i> -->
				<!-- <i> From theory to practice [mention here the LG and registration page] </i> -->
				<!-- <li>If you would like to know more about what I do or are interested in some the work shown here please do reach out! </li> -->
				</u>
				
				<!-- </td></tr></table> -->
		</header>
		<!-- <header class="row tm-welcome-section"> -->
				<!-- <h2 class="col-12 text-lefttm-section-title">Fair AI in practice</h2> -->
				<!-- <p class="col-12 text-justify"> -->
				<!-- What does it mean for an algorithm to be fair? What are the best practices for data scientists to ensure fairness in the models they design and deploy? To tackle such questions. Join the conversation in this FAIR-AI Slack community. <a href="https://join.slack.com/t/fair-ai/shared_invite/zt-edj2mqip-JZzmVGgduEjFiEpU3EXlyg"> Request an invitation</a> -->
			
		<!-- </header>		 -->
		<header class="row tm-welcome-section">
				<h2 class="col-12 text-lefttm-section-title">Fair AI: bridging theory and practice</h2>
				<p class="col-12 text-justify">
				<!-- <li class="col-12 text-justify"> -->
				What does it mean for an algorithm to be fair? What are the best practices for data scientists to ensure fairness in the models they design and deploy? 
				To tackle such questions. Join the conversation in this Fair-AI Slack community. <a href="https://join.slack.com/t/fair-ai/shared_invite/zt-edj2mqip-JZzmVGgduEjFiEpU3EXlyg">Request an invitation.</a>
				</p>
				<!-- </td></tr></table> -->
		</header>	
		
		<header class="row tm-welcome-section">
				<h2 class="col-12 text-lefttm-section-title">Forensic science </h2>
				<p class="col-12 text-justify">
				<!-- <li class="col-12 text-justify"> -->
				Although I no longer work as a forensic statistician, I am still involved in a number of initiatives. My latest contributions:
				<ul> <li> <b> How can machine learning help complex DNA profiles interpretation? </b> Using a simple classifier to determine the number of contributors to a sample can be more efficient than more traditional methods such as allele count or maxLikelihood. Check out a recent paper on this topic <a href="https://www.sciencedirect.com/science/article/abs/pii/S1872497319303436">here</a>.</li> 
				
				<li> <b> Forensic Practitioner's Guide to the Interpretation of Complex DNA Profiles </b> is a book led by Prof. Peter Gill, that centralizes a number of contributions in the field of complex DMA profile interpretation, supported by open-source software. Two of the chapters of this book relate to some of the work i have done during my time at the <a href="https://www.forensischinstituut.nl/" >NFI</a>. The book is available from <a href="https://www.elsevier.com/books/Forensic%20Practitioner's%20Guide%20to%20the%20Interpretation%20of%20Complex%20DNA%20Profiles/9780128205624?utm_campaign=ELS%20STBK%20AuthorConnect%20Release&utm_campaignPK=1695759095&utm_term=OP66802&utm_content=1695850484&utm_source=93&BID=1212165535&utm_medium=email&SIS_ID=0"> here</a>.</p>

				
				
				<!-- <table margin-left=auto margin-right=auto><tr><td width=100%> -->
			<!-- I have recently co-authored a practitioner's guide to forensic dana interpretation (only absed on open-source software), with Pprf. Peter Gill and others, co-authored the boox x and y <a href="https://www.elsevier.com/books/Forensic%20Practitioner's%20Guide%20to%20the%20Interpretation%20of%20Complex%20DNA%20Profiles/9780128205624?utm_campaign=ELS%20STBK%20AuthorConnect%20Release&utm_campaignPK=1695759095&utm_term=OP66802&utm_content=1695850484&utm_source=93&BID=1212165535&utm_medium=email&SIS_ID=0"> book stuff</a> -->	

				
				<!-- </td></tr></table> -->
		</header>			
		<header class="row tm-welcome-section">
				<h2 class="col-12 text-lefttm-section-title">Pay equality</h2>
				<p class="col-12 text-justify">
				<!-- <li class="col-12 text-justify"> -->
				An important aspect of gender equality is Equal Pay for Equal Work.
				My experience as a data scientist is that there are two main obstacles for many organizations to assess their gender pay gap: 1) poor data quality and 2) lack of available tools to compute the relevant metrics in a transparent and  interpretable way.
				I am looking into initiating a collaborative effort to demystify the pay gap analysis and offer a set of open-source tools and educational material to enable decisions-makers make progress on the topic of gender pay equality. 
				If you would like to help our or just have a chat, get in touch! I have made some basic code available <a href="https://github.com/hindantation/pay-equality"> here.</a>
				<!-- <table margin-left=auto margin-right=auto><tr><td width=100%> -->

				<!-- </td></tr></table> -->
		</header>	
		<!-- <header class="row tm-welcome-section"> -->
				<!-- <h2 class="col-12 text-lefttm-section-title">Community and outreach</h2> -->
				<!-- <p class="col-12 text-justify"> -->
				<!-- <a href="https://www.lorentzcenter.nl/accountable-machine-learning-algorithms.html">here.</a> -->
			
		<!-- </header>		 -->
		
		
				<header class="row tm-welcome-section">
				<!-- <h2 class="col-12 text-lefttm-section-title"> </h2> -->
				<p class="col-12 text-justify">
				For an up to date list of publications see my   
				 <a href="https://scholar.google.fr/citations?user=Vwnll9QAAAAJ&hl=en&authuser=1">Google Scholar page.</a> </p>
				
				<!-- </td></tr></table> -->
				</header>
		</main>

		<footer class="tm-footer text-center">
			<p>Copyright &copy; 2020 Hinda Haned
            
            | Design: <a rel="nofollow" href="https://templatemo.com">TemplateMo</a></p>
		</footer>
	<!-- </div> -->
	<script src="js/jquery.min.js"></script>
	<script src="js/parallax.min.js"></script>
</body>
</html>
